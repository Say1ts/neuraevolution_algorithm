{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0700151",
   "metadata": {},
   "source": [
    "# Нейроэволюционный алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0373fa",
   "metadata": {},
   "source": [
    "## Загружаем и подготавливаем данные для работы\n",
    "\n",
    "### Строки, не несущие информацию были удалены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea9fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "data = dt.fread('cancer1.dt')\n",
    "del data[0:7,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8246834",
   "metadata": {},
   "source": [
    "## Преробразуем данные в формат pandas.DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e522ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data.to_pandas())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30769ab3",
   "metadata": {},
   "source": [
    "## Разделяем данные на входные и требуемые выходные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ed45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = df[['C9','C10']] \\\n",
    "                    .iloc[:,0]\\\n",
    "                    .astype('int64')\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbe939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = df.iloc[:, 0:9].copy().astype('float64')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d7480",
   "metadata": {},
   "source": [
    "## Разбиваем выборку на тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ce758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, train_size = 0.8, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeeE85Xmg-En"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NeuralNetwork import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-ZLc1N_h9d8"
   },
   "source": [
    "$BLX-{\\alpha}$ кроссинговер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAv8f3b5UnDV"
   },
   "outputs": [],
   "source": [
    "def crossbreeding(nn_parent_1, nn_parent_2, BLX_ALPHA):\n",
    "    nn_child_1 = NeuralNetwork(nn_shape=nn_parent_1.nn_shape)\n",
    "    nn_child_2 = NeuralNetwork(nn_shape=nn_parent_2.nn_shape)\n",
    "    for i in range(len(nn_parent_1.weights)):\n",
    "        for j in range(len(nn_parent_1.weights[i])):\n",
    "            for k in range(len(nn_parent_1.weights[i][j])):\n",
    "                c_min = np.minimum(nn_parent_1.weights[i][j][k], nn_parent_2.weights[i][j][k])\n",
    "                c_max = np.maximum(nn_parent_1.weights[i][j][k], nn_parent_2.weights[i][j][k])\n",
    "                delta_k = c_max - c_min\n",
    "                nn_child_1.weights[i][j][k] = np.random.uniform(c_min - delta_k * BLX_ALPHA, c_max - delta_k * BLX_ALPHA)\n",
    "                nn_child_2.weights[i][j][k] = np.random.uniform(c_min - delta_k * BLX_ALPHA, c_max - delta_k * BLX_ALPHA)\n",
    "\n",
    "    return nn_child_1, nn_child_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kaa1_SO0ikPa"
   },
   "source": [
    "Функция для прямого распространения в ансамбле ИНС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdgjnk_4dSfY"
   },
   "outputs": [],
   "source": [
    "def forward_prop_ensemble(ensemble,X):\n",
    "  for count in range(len(ensemble)):\n",
    "      ensemble[count].forward_propagation(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BPglN5cizrT"
   },
   "source": [
    "\"Голосование\" ансамбля ИНС (результат вероятность)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0CXO6VHd4X6"
   },
   "outputs": [],
   "source": [
    "def ensemble_bagging_preds(ensemble):\n",
    "  F = 0\n",
    "  for count in range(len(ensemble)):\n",
    "    F += np.sum(ensemble[count].neurons[-1])/len(ensemble)\n",
    "  return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rXmcsl1jKPQ"
   },
   "source": [
    "\"Голосование\" ансамбля ИНС (дискретный результат - 0 или 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWRxnVp5k3OP"
   },
   "outputs": [],
   "source": [
    "def ensemble_bagging(ensemble):\n",
    "  F = 0\n",
    "  for count in range(len(ensemble)):\n",
    "    F += np.sum(ensemble[count].neurons[-1])/len(ensemble)\n",
    "  if F>0.5:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZvXmvqpl3C3"
   },
   "source": [
    "Функция для оценивания точности обученного классификатора на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usHB8JBUl4jT"
   },
   "outputs": [],
   "source": [
    "def ensemble_est(ensemble,X,y):\n",
    "  # размер тестового датасета\n",
    "  data_set_size = y.shape[0]\n",
    "  # количество правильно классифицированных случаев\n",
    "  correct = 0\n",
    "  for i in range(data_set_size):\n",
    "    for count in range(len(ensemble)):\n",
    "      population[count].forward_propagation(X.iloc[i,:].to_numpy())\n",
    "    prediction = ensemble_bagging(ensemble)\n",
    "    if prediction == y.iloc[i]:\n",
    "      correct +=1\n",
    "  accuracy = correct/data_set_size*100\n",
    "  print(f'accuracy: {accuracy}%')\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-15HbCOXjn_6"
   },
   "source": [
    "Основной алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество циклов эволюции\n",
    "EPOCHS = 500\n",
    "NN_SHAPE = (9,6,6,1)\n",
    "NN_POPULATION_COUNTS = 10\n",
    "BLX_ALPHA = 0.5\n",
    "MUTATION_COUNTS = 2\n",
    "# Обучающая выборка\n",
    "N = 10\n",
    "# константа корреляции\n",
    "CORRELATION_CONSTANT = 0.4\n",
    "\n",
    "# формирование начальной популяции\n",
    "population = []\n",
    "\n",
    "# количество мутаций\n",
    "\n",
    "\n",
    "model_accuracy_array = []\n",
    "epochs_array = []\n",
    "\n",
    "# инициализация начальной популяции\n",
    "for count in range(NN_POPULATION_COUNTS):\n",
    "  neural_network = NeuralNetwork(nn_shape=NN_SHAPE)\n",
    "  population.append(neural_network)\n",
    "\n",
    "error_f = np.zeros(len(population))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# получаем двух особей усечением (лучшая половина популяции)\n",
    "\n",
    "def cut_selection():\n",
    "    individual_1 = 0\n",
    "    individual_2 = 0\n",
    "    while individual_1 == individual_2:\n",
    "        individual_1 = np.random.randint(0,NN_POPULATION_COUNTS/2)\n",
    "        individual_2 = np.random.randint(0,NN_POPULATION_COUNTS/2)\n",
    "    return individual_1, individual_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0doL45lrCUMy",
    "outputId": "3d373604-fb2f-4700-8fa0-5971916d08e6"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  sort_indx = error_f.argsort() # индексы отсортированных элементов\n",
    "\n",
    "  individual_1, individual_2 = cut_selection()\n",
    "  \n",
    "  # Кроссинговер BLX-a. Получаем двух потомков от двух родителей\n",
    "  nn_child_1, nn_child_2 = crossbreeding(population[sort_indx[individual_1]],\n",
    "                                         population[sort_indx[individual_2]],BLX_ALPHA)\n",
    "\n",
    "  # Удаляем особи с наибольшим значением функции ошибки\n",
    "  if sort_indx[-1]>sort_indx[-2]:\n",
    "    population.remove(population[sort_indx[-1]])\n",
    "    population.remove(population[sort_indx[-2]])\n",
    "  else:\n",
    "    population.remove(population[sort_indx[-2]])\n",
    "    population.remove(population[sort_indx[-1]])\n",
    "\n",
    "  population.append(nn_child_1)\n",
    "  population.append(nn_child_2)\n",
    "\n",
    "  # Гауссовская мутация\n",
    "  for mut_count in range(MUTATION_COUNTS):\n",
    "    mut = np.random.randint(0,len(population))\n",
    "    population[mut].mutation()\n",
    "  # Обнулим массив значений функции ошибок\n",
    "  error_f[:]=0\n",
    "  # Цикл обучения\n",
    "  for learning_cycle in range(N):\n",
    "    #выбираем случайный индекс элемент тренировочного датасета\n",
    "    df_index = np.random.randint(0,X_train.shape[0])\n",
    "    # входные данные\n",
    "    piece_of_data = X_train.iloc[df_index,:].to_numpy()\n",
    "    # желаемый отклик\n",
    "    d = y_train.iloc[df_index]\n",
    "    p = np.zeros_like(error_f)\n",
    "    # прямое распространение для всей популяции\n",
    "    forward_prop_ensemble(population,piece_of_data)\n",
    "\n",
    "    # общий вывод популяции\n",
    "    F = ensemble_bagging_preds(population)\n",
    "\n",
    "    # расчёт функции корреляционного штрафа\n",
    "    for count in range(len(population)):\n",
    "      for count_p in range(len(population)):\n",
    "        if count_p != count:\n",
    "          p[count] += (population[count].neurons[-1]-F)*(population[count_p].neurons[-1]-F)\n",
    "      error_f[count]+=1/N/2*(population[count].neurons[-1]-d)**2+1/N*CORRELATION_CONSTANT*p[count]\n",
    "  if epoch%50==0:\n",
    "    epochs_array.append(epoch)\n",
    "    print(f'epoch: {epoch}')\n",
    "    model_accuracy_array.append(ensemble_est(population,X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeQLiBrscgBV"
   },
   "source": [
    "Далее оценим точность классификатора на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7eF801Voy-0",
    "outputId": "1eddc74e-eac0-47cd-b7b2-d0023c5f396d"
   },
   "outputs": [],
   "source": [
    "ensemble_est(population,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIuyeKmGu0jP"
   },
   "source": [
    "График обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "V_2L7gzBu0_m",
    "outputId": "ed3225c2-3c81-41dd-ceb5-f4095a7d3e1e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs_array, model_accuracy_array, c='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0ueErKKfOOB"
   },
   "source": [
    "Демонстрация вероятностного вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVRJlTvtfHx3",
    "outputId": "ecefffd2-16cf-4bca-916a-1770659da779"
   },
   "outputs": [],
   "source": [
    "df_index = np.random.randint(0,X_test.shape[0])\n",
    "piece_of_data = X_test.iloc[df_index,:].to_numpy()\n",
    "d = y_test.iloc[df_index]\n",
    "for count in range(len(population)):\n",
    "  population[count].forward_propagation(piece_of_data)\n",
    "F = ensemble_bagging_preds(population)\n",
    "print(d)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7OrShgazki4"
   },
   "source": [
    "Функция для вывода весов связей в отдельный файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKO55gIAz89M"
   },
   "outputs": [],
   "source": [
    "def save_weights(ensemble):\n",
    "  file = open('NN_ensemble_structure.txt','w')\n",
    "  for nn in range(len(ensemble)):\n",
    "    file.write('\\n########################\\n')\n",
    "    for i in range(len(ensemble[nn].weights)):\n",
    "      for j in range(len(ensemble[nn].weights[i])):\n",
    "        for k in range(len(ensemble[nn].weights[i][j])):\n",
    "          file.write(str(ensemble[nn].weights[i][j][k])+' ')\n",
    "        file.write('\\n')\n",
    "  file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7XtDK9b2CJn"
   },
   "outputs": [],
   "source": [
    "save_weights(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2MkTsZq4Lik"
   },
   "source": [
    "Функция для записи весов смещения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wp7AEXYC2EJK"
   },
   "outputs": [],
   "source": [
    "def save_bias(ensemble):\n",
    "  file = open('NN_ensemble_bias.txt','w')\n",
    "  for nn in range(len(ensemble)):\n",
    "    file.write('\\n########################\\n')\n",
    "    for i in range(len(ensemble[nn].biases)):\n",
    "      for j in range(len(ensemble[nn].biases[i])):\n",
    "        file.write(str(ensemble[nn].biases[i][j])+' ')\n",
    "      file.write('\\n')\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9T5UPXFj4m54"
   },
   "outputs": [],
   "source": [
    "save_bias(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOE/e3uoa8OExU4dIKeMFRi",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NCL_Khayrov.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
